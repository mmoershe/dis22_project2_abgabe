{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79de9524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 13401\n",
      "Queries ending with '?': 3880\n",
      "Queries starting with W-question words: 9731 (72.61%)\n",
      "Queries not starting with W-question words: 3670 (27.39%)\n",
      "Queries containing numbers: 2983 (22.26%)\n",
      "\n",
      "Average query length: 79.05 characters, 11.30 words\n",
      "\n",
      "Top 10 most common 1-word start phrases:\n",
      "  how: 5212x\n",
      "  what: 2970x\n",
      "  why: 1090x\n",
      "  is: 406x\n",
      "  does: 394x\n",
      "  do: 379x\n",
      "  can: 351x\n",
      "  are: 294x\n",
      "  when: 244x\n",
      "  who: 124x\n",
      "\n",
      "Top 10 most common 2-word start phrases:\n",
      "  what is: 1459x\n",
      "  how to: 1301x\n",
      "  how does: 820x\n",
      "  what are: 514x\n",
      "  how do: 507x\n",
      "  how can: 243x\n",
      "  what situations: 154x\n",
      "  do not: 153x\n",
      "  why is: 148x\n",
      "  why do: 135x\n",
      "\n",
      "Top 10 most common query lengths:\n",
      "  Length 48: 262 queries\n",
      "  Length 94: 233 queries\n",
      "  Length 46: 215 queries\n",
      "  Length 79: 213 queries\n",
      "  Length 96: 205 queries\n",
      "  Length 91: 188 queries\n",
      "  Length 104: 186 queries\n",
      "  Length 88: 185 queries\n",
      "  Length 108: 182 queries\n",
      "  Length 106: 181 queries\n",
      "\n",
      "Most common query length: 48\n",
      "\n",
      "Most frequent question patterns (of interest):\n",
      "  what is: 1459x\n",
      "  how to: 1301x\n",
      "  how does: 820x\n",
      "  how do: 507x\n",
      "  why does: 45x\n",
      "  can i: 7x\n",
      "  does it: 3x\n",
      "  what are: 514x\n",
      "  why is: 148x\n",
      "  why do: 135x\n",
      "\n",
      "Top 10 start words for non-W queries:\n",
      "  is: 406x\n",
      "  does: 394x\n",
      "  do: 379x\n",
      "  can: 351x\n",
      "  are: 294x\n",
      "  the: 109x\n",
      "  should: 43x\n",
      "  a: 36x\n",
      "  what's: 28x\n",
      "  will: 26x\n",
      "\n",
      "Sample non-W-query patterns (first 5 words):\n",
      "  ¿es posible un aporte del...\n",
      "  can christians experience demon possession?...\n",
      "  do remittance promote economic growth...\n",
      "  is the ‘new’ parmalat model...\n",
      "  do ko gyi kyaw: analyzing...\n",
      "  if you are going to...\n",
      "  can artifical intelligence replace teacher...\n",
      "  the moon disappeared?...\n",
      "  will energy infrastructure systems in...\n",
      "  are all bioplastic materials biodegradable...\n",
      "\n",
      "Query-Endzeichen (außer '?'):\n",
      "  ')': 2131x\n",
      "  '.': 383x\n",
      "  '\"': 364x\n",
      "  '*': 6x\n",
      "  '/': 5x\n",
      "  ':': 3x\n",
      "  '”': 2x\n",
      "  '’': 2x\n",
      "  '>': 2x\n",
      "  '★': 1x\n",
      "\n",
      "Queries ohne jegliches Satzzeichen am Ende: 6620 (49.40%)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_cluster_file(file_path):\n",
    "    total_queries = 0\n",
    "    start_word_1gram = Counter()\n",
    "    start_word_2gram = Counter()\n",
    "    end_question_count = 0\n",
    "    length_distribution = Counter()\n",
    "    total_length_chars = 0\n",
    "    total_length_words = 0\n",
    "    queries_with_numbers = 0\n",
    "    w_question_starts = 0\n",
    "\n",
    "    # Neue Counter\n",
    "    non_w_start_counter = Counter()\n",
    "    non_w_queries = []\n",
    "    end_char_counter = Counter()\n",
    "    no_end_punctuation = 0\n",
    "\n",
    "    # W-Fragewörter\n",
    "    w_question_words = {\"what\", \"when\", \"where\", \"why\", \"who\", \"how\", \"which\", \"whose\", \"whom\"}\n",
    "\n",
    "    # Häufige Fragephrasen\n",
    "    frequent_patterns = [\n",
    "        \"what is\", \"how to\", \"how does\", \"how do\", \"why does\", \"can i\",\n",
    "        \"does it\", \"what are\", \"why is\", \"why do\"\n",
    "    ]\n",
    "    pattern_counter = Counter()\n",
    "\n",
    "    # Regex\n",
    "    number_pattern = re.compile(r'\\d+')\n",
    "    question_mark_pattern = re.compile(r'\\?$')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        next(reader)  \n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "\n",
    "            query = row[1].strip()\n",
    "            if not query:\n",
    "                continue\n",
    "\n",
    "            total_queries += 1\n",
    "            words = query.lower().split()\n",
    "            total_length_chars += len(query)\n",
    "            total_length_words += len(words)\n",
    "\n",
    "            if number_pattern.search(query):\n",
    "                queries_with_numbers += 1\n",
    "\n",
    "            if question_mark_pattern.search(query):\n",
    "                end_question_count += 1\n",
    "            else:\n",
    "               \n",
    "                last_char = query[-1]\n",
    "                if last_char.isalnum():\n",
    "                    no_end_punctuation += 1\n",
    "                else:\n",
    "                    end_char_counter[last_char] += 1\n",
    "\n",
    "            if words:\n",
    "                start_word = words[0]\n",
    "                start_word_1gram[start_word] += 1\n",
    "\n",
    "                if start_word in w_question_words:\n",
    "                    w_question_starts += 1\n",
    "                else:\n",
    "                    non_w_start_counter[start_word] += 1\n",
    "                    non_w_queries.append(' '.join(words[:5]))\n",
    "\n",
    "                if len(words) > 1:\n",
    "                    first_two = f\"{words[0]} {words[1]}\"\n",
    "                    start_word_2gram[first_two] += 1\n",
    "                    if first_two in frequent_patterns:\n",
    "                        pattern_counter[first_two] += 1\n",
    "\n",
    "            length_distribution[len(query)] += 1\n",
    "\n",
    " \n",
    "    top_1grams = start_word_1gram.most_common(10)\n",
    "    top_2grams = start_word_2gram.most_common(10)\n",
    "    top_lengths = length_distribution.most_common(10)\n",
    "    avg_chars = total_length_chars / total_queries\n",
    "    avg_words = total_length_words / total_queries\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Total queries: {total_queries}\")\n",
    "    print(f\"Queries ending with '?': {end_question_count}\")\n",
    "    print(f\"Queries starting with W-question words: {w_question_starts} ({w_question_starts / total_queries:.2%})\")\n",
    "    print(f\"Queries not starting with W-question words: {total_queries - w_question_starts} ({(total_queries - w_question_starts) / total_queries:.2%})\")\n",
    "    print(f\"Queries containing numbers: {queries_with_numbers} ({queries_with_numbers / total_queries:.2%})\")\n",
    "    print(f\"\\nAverage query length: {avg_chars:.2f} characters, {avg_words:.2f} words\")\n",
    "\n",
    "    print(\"\\nTop 10 most common 1-word start phrases:\")\n",
    "    for word, count in top_1grams:\n",
    "        print(f\"  {word}: {count}x\")\n",
    "\n",
    "    print(\"\\nTop 10 most common 2-word start phrases:\")\n",
    "    for phrase, count in top_2grams:\n",
    "        print(f\"  {phrase}: {count}x\")\n",
    "\n",
    "    print(\"\\nTop 10 most common query lengths:\")\n",
    "    for length, count in top_lengths:\n",
    "        print(f\"  Length {length}: {count} queries\")\n",
    "\n",
    "    print(f\"\\nMost common query length: {top_lengths[0][0] if top_lengths else 'N/A'}\")\n",
    "\n",
    "    print(\"\\nMost frequent question patterns (of interest):\")\n",
    "    for phrase in frequent_patterns:\n",
    "        print(f\"  {phrase}: {pattern_counter[phrase]}x\")\n",
    "\n",
    "    print(\"\\nTop 10 start words for non-W queries:\")\n",
    "    for word, count in non_w_start_counter.most_common(10):\n",
    "        print(f\"  {word}: {count}x\")\n",
    "\n",
    "    print(\"\\nSample non-W-query patterns (first 5 words):\")\n",
    "    for example in non_w_queries[:10]:\n",
    "        print(f\"  {example}...\")\n",
    "\n",
    "    print(\"\\nQuery-Endzeichen (außer '?'):\")\n",
    "    for char, count in end_char_counter.most_common(10):\n",
    "        readable = repr(char)\n",
    "        print(f\"  {readable}: {count}x\")\n",
    "\n",
    "    print(f\"\\nQueries ohne jegliches Satzzeichen am Ende: {no_end_punctuation} ({no_end_punctuation / total_queries:.2%})\")\n",
    "\n",
    "file_path = 'cluster3.tsv'  \n",
    "analyze_cluster_file(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
